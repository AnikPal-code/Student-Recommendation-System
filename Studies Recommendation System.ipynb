{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id first_name last_name                                  email  gender  \\\n0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n\n   part_time_job  absence_days  extracurricular_activities  \\\n0          False             3                       False   \n1          False             2                       False   \n2          False             9                        True   \n3          False             5                       False   \n4          False             5                       False   \n\n   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n0                       27              Lawyer          73             81   \n1                       47              Doctor          90             86   \n2                       13  Government Officer          81             97   \n3                        3              Artist          71             74   \n4                       10             Unknown          84             77   \n\n   physics_score  chemistry_score  biology_score  english_score  \\\n0             93               97             63             80   \n1             96              100             90             88   \n2             95               96             65             77   \n3             88               80             89             63   \n4             65               65             80             74   \n\n   geography_score  \n0               87  \n1               90  \n2               94  \n3               86  \n4               76  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>first_name</th>\n      <th>last_name</th>\n      <th>email</th>\n      <th>gender</th>\n      <th>part_time_job</th>\n      <th>absence_days</th>\n      <th>extracurricular_activities</th>\n      <th>weekly_self_study_hours</th>\n      <th>career_aspiration</th>\n      <th>math_score</th>\n      <th>history_score</th>\n      <th>physics_score</th>\n      <th>chemistry_score</th>\n      <th>biology_score</th>\n      <th>english_score</th>\n      <th>geography_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Paul</td>\n      <td>Casey</td>\n      <td>paul.casey.1@gslingacademy.com</td>\n      <td>male</td>\n      <td>False</td>\n      <td>3</td>\n      <td>False</td>\n      <td>27</td>\n      <td>Lawyer</td>\n      <td>73</td>\n      <td>81</td>\n      <td>93</td>\n      <td>97</td>\n      <td>63</td>\n      <td>80</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Danielle</td>\n      <td>Sandoval</td>\n      <td>danielle.sandoval.2@gslingacademy.com</td>\n      <td>female</td>\n      <td>False</td>\n      <td>2</td>\n      <td>False</td>\n      <td>47</td>\n      <td>Doctor</td>\n      <td>90</td>\n      <td>86</td>\n      <td>96</td>\n      <td>100</td>\n      <td>90</td>\n      <td>88</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Tina</td>\n      <td>Andrews</td>\n      <td>tina.andrews.3@gslingacademy.com</td>\n      <td>female</td>\n      <td>False</td>\n      <td>9</td>\n      <td>True</td>\n      <td>13</td>\n      <td>Government Officer</td>\n      <td>81</td>\n      <td>97</td>\n      <td>95</td>\n      <td>96</td>\n      <td>65</td>\n      <td>77</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Tara</td>\n      <td>Clark</td>\n      <td>tara.clark.4@gslingacademy.com</td>\n      <td>female</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>3</td>\n      <td>Artist</td>\n      <td>71</td>\n      <td>74</td>\n      <td>88</td>\n      <td>80</td>\n      <td>89</td>\n      <td>63</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Anthony</td>\n      <td>Campos</td>\n      <td>anthony.campos.5@gslingacademy.com</td>\n      <td>male</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10</td>\n      <td>Unknown</td>\n      <td>84</td>\n      <td>77</td>\n      <td>65</td>\n      <td>65</td>\n      <td>80</td>\n      <td>74</td>\n      <td>76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"student-scores.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'first_name', 'last_name', 'email'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   gender  part_time_job  absence_days  extracurricular_activities  \\\n0    male          False             3                       False   \n1  female          False             2                       False   \n2  female          False             9                        True   \n3  female          False             5                       False   \n4    male          False             5                       False   \n\n   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n0                       27              Lawyer          73             81   \n1                       47              Doctor          90             86   \n2                       13  Government Officer          81             97   \n3                        3              Artist          71             74   \n4                       10             Unknown          84             77   \n\n   physics_score  chemistry_score  biology_score  english_score  \\\n0             93               97             63             80   \n1             96              100             90             88   \n2             95               96             65             77   \n3             88               80             89             63   \n4             65               65             80             74   \n\n   geography_score  \n0               87  \n1               90  \n2               94  \n3               86  \n4               76  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>part_time_job</th>\n      <th>absence_days</th>\n      <th>extracurricular_activities</th>\n      <th>weekly_self_study_hours</th>\n      <th>career_aspiration</th>\n      <th>math_score</th>\n      <th>history_score</th>\n      <th>physics_score</th>\n      <th>chemistry_score</th>\n      <th>biology_score</th>\n      <th>english_score</th>\n      <th>geography_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>False</td>\n      <td>3</td>\n      <td>False</td>\n      <td>27</td>\n      <td>Lawyer</td>\n      <td>73</td>\n      <td>81</td>\n      <td>93</td>\n      <td>97</td>\n      <td>63</td>\n      <td>80</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>False</td>\n      <td>2</td>\n      <td>False</td>\n      <td>47</td>\n      <td>Doctor</td>\n      <td>90</td>\n      <td>86</td>\n      <td>96</td>\n      <td>100</td>\n      <td>90</td>\n      <td>88</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>False</td>\n      <td>9</td>\n      <td>True</td>\n      <td>13</td>\n      <td>Government Officer</td>\n      <td>81</td>\n      <td>97</td>\n      <td>95</td>\n      <td>96</td>\n      <td>65</td>\n      <td>77</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>3</td>\n      <td>Artist</td>\n      <td>71</td>\n      <td>74</td>\n      <td>88</td>\n      <td>80</td>\n      <td>89</td>\n      <td>63</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>male</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10</td>\n      <td>Unknown</td>\n      <td>84</td>\n      <td>77</td>\n      <td>65</td>\n      <td>65</td>\n      <td>80</td>\n      <td>74</td>\n      <td>76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   gender  part_time_job  absence_days  extracurricular_activities  \\\n0    male          False             3                       False   \n1  female          False             2                       False   \n2  female          False             9                        True   \n3  female          False             5                       False   \n4    male          False             5                       False   \n\n   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n0                       27              Lawyer          73             81   \n1                       47              Doctor          90             86   \n2                       13  Government Officer          81             97   \n3                        3              Artist          71             74   \n4                       10             Unknown          84             77   \n\n   physics_score  chemistry_score  biology_score  english_score  \\\n0             93               97             63             80   \n1             96              100             90             88   \n2             95               96             65             77   \n3             88               80             89             63   \n4             65               65             80             74   \n\n   geography_score  total_score  average_score  \n0               87          574      82.000000  \n1               90          640      91.428571  \n2               94          605      86.428571  \n3               86          551      78.714286  \n4               76          521      74.428571  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>part_time_job</th>\n      <th>absence_days</th>\n      <th>extracurricular_activities</th>\n      <th>weekly_self_study_hours</th>\n      <th>career_aspiration</th>\n      <th>math_score</th>\n      <th>history_score</th>\n      <th>physics_score</th>\n      <th>chemistry_score</th>\n      <th>biology_score</th>\n      <th>english_score</th>\n      <th>geography_score</th>\n      <th>total_score</th>\n      <th>average_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>False</td>\n      <td>3</td>\n      <td>False</td>\n      <td>27</td>\n      <td>Lawyer</td>\n      <td>73</td>\n      <td>81</td>\n      <td>93</td>\n      <td>97</td>\n      <td>63</td>\n      <td>80</td>\n      <td>87</td>\n      <td>574</td>\n      <td>82.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>False</td>\n      <td>2</td>\n      <td>False</td>\n      <td>47</td>\n      <td>Doctor</td>\n      <td>90</td>\n      <td>86</td>\n      <td>96</td>\n      <td>100</td>\n      <td>90</td>\n      <td>88</td>\n      <td>90</td>\n      <td>640</td>\n      <td>91.428571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>False</td>\n      <td>9</td>\n      <td>True</td>\n      <td>13</td>\n      <td>Government Officer</td>\n      <td>81</td>\n      <td>97</td>\n      <td>95</td>\n      <td>96</td>\n      <td>65</td>\n      <td>77</td>\n      <td>94</td>\n      <td>605</td>\n      <td>86.428571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>3</td>\n      <td>Artist</td>\n      <td>71</td>\n      <td>74</td>\n      <td>88</td>\n      <td>80</td>\n      <td>89</td>\n      <td>63</td>\n      <td>86</td>\n      <td>551</td>\n      <td>78.714286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>male</td>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10</td>\n      <td>Unknown</td>\n      <td>84</td>\n      <td>77</td>\n      <td>65</td>\n      <td>65</td>\n      <td>80</td>\n      <td>74</td>\n      <td>76</td>\n      <td>521</td>\n      <td>74.428571</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_score'] = df['math_score']+df['physics_score']+df['chemistry_score']+df['biology_score']+df['english_score']+df['geography_score']+df['history_score']\n",
    "df['average_score'] = df['total_score']/7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(career_aspiration\n Software Engineer        315\n Business Owner           309\n Unknown                  223\n Banker                   169\n Lawyer                   138\n Accountant               126\n Doctor                   119\n Real Estate Developer     83\n Stock Investor            73\n Construction Engineer     68\n Artist                    67\n Game Developer            63\n Government Officer        61\n Teacher                   59\n Designer                  56\n Scientist                 39\n Writer                    32\n Name: count, dtype: int64,\n array(['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n        'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n        'Banker', 'Writer', 'Accountant', 'Designer',\n        'Construction Engineer', 'Game Developer', 'Stock Investor',\n        'Real Estate Developer'], dtype=object))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts(), df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['career_aspiration'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define mapping dictionaries\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "    'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "    'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "    'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "    'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "    'Real Estate Developer': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   gender  part_time_job  absence_days  extracurricular_activities  \\\n0       0              0             3                           0   \n1       1              0             2                           0   \n2       1              0             9                           1   \n3       1              0             5                           0   \n4       0              0             5                           0   \n\n   weekly_self_study_hours  career_aspiration  math_score  history_score  \\\n0                       27                  0          73             81   \n1                       47                  1          90             86   \n2                       13                  2          81             97   \n3                        3                  3          71             74   \n4                       10                  4          84             77   \n\n   physics_score  chemistry_score  biology_score  english_score  \\\n0             93               97             63             80   \n1             96              100             90             88   \n2             95               96             65             77   \n3             88               80             89             63   \n4             65               65             80             74   \n\n   geography_score  total_score  average_score  \n0               87          574      82.000000  \n1               90          640      91.428571  \n2               94          605      86.428571  \n3               86          551      78.714286  \n4               76          521      74.428571  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>part_time_job</th>\n      <th>absence_days</th>\n      <th>extracurricular_activities</th>\n      <th>weekly_self_study_hours</th>\n      <th>career_aspiration</th>\n      <th>math_score</th>\n      <th>history_score</th>\n      <th>physics_score</th>\n      <th>chemistry_score</th>\n      <th>biology_score</th>\n      <th>english_score</th>\n      <th>geography_score</th>\n      <th>total_score</th>\n      <th>average_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>27</td>\n      <td>0</td>\n      <td>73</td>\n      <td>81</td>\n      <td>93</td>\n      <td>97</td>\n      <td>63</td>\n      <td>80</td>\n      <td>87</td>\n      <td>574</td>\n      <td>82.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>47</td>\n      <td>1</td>\n      <td>90</td>\n      <td>86</td>\n      <td>96</td>\n      <td>100</td>\n      <td>90</td>\n      <td>88</td>\n      <td>90</td>\n      <td>640</td>\n      <td>91.428571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>81</td>\n      <td>97</td>\n      <td>95</td>\n      <td>96</td>\n      <td>65</td>\n      <td>77</td>\n      <td>94</td>\n      <td>605</td>\n      <td>86.428571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>71</td>\n      <td>74</td>\n      <td>88</td>\n      <td>80</td>\n      <td>89</td>\n      <td>63</td>\n      <td>86</td>\n      <td>551</td>\n      <td>78.714286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>84</td>\n      <td>77</td>\n      <td>65</td>\n      <td>65</td>\n      <td>80</td>\n      <td>74</td>\n      <td>76</td>\n      <td>521</td>\n      <td>74.428571</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 15)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "career_aspiration\n5     315\n7     309\n4     223\n9     169\n0     138\n11    126\n1     119\n16     83\n15     73\n13     68\n3      67\n14     63\n2      61\n6      59\n12     56\n8      39\n10     32\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "career_aspiration\n0     315\n9     315\n15    315\n14    315\n13    315\n12    315\n11    315\n10    315\n8     315\n1     315\n7     315\n6     315\n5     315\n4     315\n3     315\n2     315\n16    315\nName: count, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(5355,)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "      gender  part_time_job  absence_days  extracurricular_activities  \\\n2369       1              0             3                           0   \n3955       1              0             3                           0   \n3785       1              0             1                           0   \n120        1              1             0                           0   \n3699       1              0             3                           0   \n...      ...            ...           ...                         ...   \n3092       1              0             2                           0   \n3772       0              0             2                           0   \n5191       0              0             5                           0   \n5226       1              0             3                           0   \n860        0              0             4                           0   \n\n      weekly_self_study_hours  math_score  history_score  physics_score  \\\n2369                       38          96             93             93   \n3955                       29          95             77             93   \n3785                       16          71             99             98   \n120                        13          66             90             83   \n3699                       21          68             77             82   \n...                       ...         ...            ...            ...   \n3092                       11          65             73             92   \n3772                       21          71             72             84   \n5191                        3          87             77             64   \n5226                        4          75             91             67   \n860                        25         100             62             78   \n\n      chemistry_score  biology_score  english_score  geography_score  \\\n2369               90             87             87               90   \n3955               85             47             69               74   \n3785               95             91             95               95   \n120                80             76             90               91   \n3699               92             92             90               71   \n...               ...            ...            ...              ...   \n3092               61             93             92               86   \n3772               89             74             93               65   \n5191               83             83             93               79   \n5226               86             79             72               88   \n860                74             72             73               78   \n\n      total_score  average_score  \n2369          639      91.386647  \n3955          542      77.464726  \n3785          648      92.576635  \n120           576      82.285714  \n3699          574      82.071885  \n...           ...            ...  \n3092          565      80.807391  \n3772          551      78.854845  \n5191          569      81.405332  \n5226          562      80.361061  \n860           537      76.714286  \n\n[4284 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>part_time_job</th>\n      <th>absence_days</th>\n      <th>extracurricular_activities</th>\n      <th>weekly_self_study_hours</th>\n      <th>math_score</th>\n      <th>history_score</th>\n      <th>physics_score</th>\n      <th>chemistry_score</th>\n      <th>biology_score</th>\n      <th>english_score</th>\n      <th>geography_score</th>\n      <th>total_score</th>\n      <th>average_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2369</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>38</td>\n      <td>96</td>\n      <td>93</td>\n      <td>93</td>\n      <td>90</td>\n      <td>87</td>\n      <td>87</td>\n      <td>90</td>\n      <td>639</td>\n      <td>91.386647</td>\n    </tr>\n    <tr>\n      <th>3955</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>29</td>\n      <td>95</td>\n      <td>77</td>\n      <td>93</td>\n      <td>85</td>\n      <td>47</td>\n      <td>69</td>\n      <td>74</td>\n      <td>542</td>\n      <td>77.464726</td>\n    </tr>\n    <tr>\n      <th>3785</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16</td>\n      <td>71</td>\n      <td>99</td>\n      <td>98</td>\n      <td>95</td>\n      <td>91</td>\n      <td>95</td>\n      <td>95</td>\n      <td>648</td>\n      <td>92.576635</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>66</td>\n      <td>90</td>\n      <td>83</td>\n      <td>80</td>\n      <td>76</td>\n      <td>90</td>\n      <td>91</td>\n      <td>576</td>\n      <td>82.285714</td>\n    </tr>\n    <tr>\n      <th>3699</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>21</td>\n      <td>68</td>\n      <td>77</td>\n      <td>82</td>\n      <td>92</td>\n      <td>92</td>\n      <td>90</td>\n      <td>71</td>\n      <td>574</td>\n      <td>82.071885</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3092</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>11</td>\n      <td>65</td>\n      <td>73</td>\n      <td>92</td>\n      <td>61</td>\n      <td>93</td>\n      <td>92</td>\n      <td>86</td>\n      <td>565</td>\n      <td>80.807391</td>\n    </tr>\n    <tr>\n      <th>3772</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>21</td>\n      <td>71</td>\n      <td>72</td>\n      <td>84</td>\n      <td>89</td>\n      <td>74</td>\n      <td>93</td>\n      <td>65</td>\n      <td>551</td>\n      <td>78.854845</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>87</td>\n      <td>77</td>\n      <td>64</td>\n      <td>83</td>\n      <td>83</td>\n      <td>93</td>\n      <td>79</td>\n      <td>569</td>\n      <td>81.405332</td>\n    </tr>\n    <tr>\n      <th>5226</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>75</td>\n      <td>91</td>\n      <td>67</td>\n      <td>86</td>\n      <td>79</td>\n      <td>72</td>\n      <td>88</td>\n      <td>562</td>\n      <td>80.361061</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>25</td>\n      <td>100</td>\n      <td>62</td>\n      <td>78</td>\n      <td>74</td>\n      <td>72</td>\n      <td>73</td>\n      <td>78</td>\n      <td>537</td>\n      <td>76.714286</td>\n    </tr>\n  </tbody>\n</table>\n<p>4284 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.77671965, -0.27243837,  1.453168  , ..., -0.28806196,\n        -0.97030312, -0.96016972],\n       [ 1.28746582,  3.67055486,  1.453168  , ...,  1.14644374,\n        -0.5211787 , -0.52879507],\n       [ 1.28746582, -0.27243837, -0.92656125, ..., -0.47932938,\n         0.35065104,  0.34232811],\n       ...,\n       [-0.77671965, -0.27243837, -0.92656125, ...,  0.19010661,\n        -0.70611229, -0.70582899],\n       [-0.77671965, -0.27243837,  0.5012763 , ..., -1.05313166,\n        -0.91746495, -0.90650981],\n       [-0.77671965, -0.27243837,  1.92911386, ...,  1.81587973,\n        -0.01921612, -0.0272393 ]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe\\lib\\site-packages (2.1.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.49019607843137253\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51        68\n",
      "           1       0.51      0.57      0.54        72\n",
      "           2       0.43      0.44      0.43        57\n",
      "           3       0.51      0.60      0.56        58\n",
      "           4       0.29      0.17      0.21        66\n",
      "           5       0.31      0.29      0.30        76\n",
      "           6       0.60      0.94      0.73        71\n",
      "           7       0.84      0.92      0.88        61\n",
      "           8       0.41      0.57      0.47        53\n",
      "           9       0.25      0.10      0.14        61\n",
      "          10       0.57      0.71      0.63        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.30      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.91      0.73        57\n",
      "          15       0.36      0.22      0.27        63\n",
      "          16       0.56      0.33      0.42        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.47      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36  3  0  0  0  7  0  0  5  1 10  4  0  2  0  0  0]\n",
      " [ 2 41  0  0  0  6  0  0 18  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  0  0  0  2  0  5  1  2  2  4]\n",
      " [ 0  0  2 35  0  0  1  1  0  0  0  0  0  0 10  0  9]\n",
      " [ 5  4  8  3 11  9  7  1  4  3  0  3  3  2  1  1  1]\n",
      " [ 6  9  0  0  2 22  1  0  2  9  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  1 67  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 56  0  0  0  0  0  0  3  0  0]\n",
      " [ 3 12  0  0  0  1  0  0 30  0  6  0  0  1  0  0  0]\n",
      " [ 9  1  0  0  3  8  8  0  1  6  3  7  6  6  0  3  0]\n",
      " [ 7  2  0  0  1  0  3  0  2  2 45  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  5  6  3  0  4  1  0 24  1  2  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  3  0  3  0  0  0  5  1  1  4  4 27  0  4  0]\n",
      " [ 0  0  0  4  0  0  0  0  0  0  0  0  0  0 52  0  1]\n",
      " [ 3  3  3  0  6  6  1  3  0  1  3  7  4  7  1 14  1]\n",
      " [ 0  0  9 16  0  1  5  6  0  0  2  0  0  0  7  0 23]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6442577030812325\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58        68\n",
      "           1       0.61      0.83      0.70        72\n",
      "           2       0.62      0.74      0.67        57\n",
      "           3       0.68      0.88      0.77        58\n",
      "           4       0.48      0.20      0.28        66\n",
      "           5       0.41      0.29      0.34        76\n",
      "           6       0.70      0.94      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.66      0.81      0.73        53\n",
      "           9       0.37      0.31      0.34        61\n",
      "          10       0.81      0.86      0.83        63\n",
      "          11       0.84      0.49      0.62        53\n",
      "          12       0.67      0.53      0.59        68\n",
      "          13       0.52      0.85      0.64        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.61      0.43      0.50        63\n",
      "          16       0.75      0.48      0.58        69\n",
      "\n",
      "    accuracy                           0.64      1071\n",
      "   macro avg       0.64      0.65      0.63      1071\n",
      "weighted avg       0.64      0.64      0.62      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[40  5  0  0  0  5  0  0  2  4  7  1  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  0  4  0  0  0  0  0  2  0  0  4  1]\n",
      " [ 0  0  1 51  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 3  7  7  1 13  7  5  2  1  7  2  1  5  3  1  1  0]\n",
      " [10  8  1  0  2 22  2  1  4 11  0  1  1 12  0  1  0]\n",
      " [ 0  0  0  0  0  0 67  0  0  1  1  0  0  0  0  1  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 7  1  1  0  1  6  7  1  3 19  1  0  4  6  0  4  0]\n",
      " [ 1  1  4  0  0  0  0  0  0  2 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  3  1 26  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  0  7  0  2  0  1  1 36  3  4  1  5]\n",
      " [ 0  3  0  0  1  1  0  0  2  1  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  0  0 53  0  1]\n",
      " [ 5  2  3  1  2  4  0  0  0  3  0  1  4 10  1 27  0]\n",
      " [ 0  0  8 16  1  2  2  1  0  0  0  0  0  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8207282913165266\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77        68\n",
      "           1       0.76      1.00      0.86        72\n",
      "           2       0.80      0.98      0.88        57\n",
      "           3       0.86      0.95      0.90        58\n",
      "           4       0.76      0.47      0.58        66\n",
      "           5       0.54      0.36      0.43        76\n",
      "           6       0.91      1.00      0.95        71\n",
      "           7       0.94      0.95      0.94        61\n",
      "           8       0.71      0.85      0.78        53\n",
      "           9       0.69      0.72      0.70        61\n",
      "          10       0.90      1.00      0.95        63\n",
      "          11       0.84      0.72      0.78        53\n",
      "          12       0.92      0.84      0.88        68\n",
      "          13       0.77      0.96      0.85        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.89      0.67      0.76        63\n",
      "          16       0.95      0.84      0.89        69\n",
      "\n",
      "    accuracy                           0.82      1071\n",
      "   macro avg       0.82      0.83      0.82      1071\n",
      "weighted avg       0.82      0.82      0.81      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53  4  0  0  1  4  0  0  2  1  3  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 3  3  8  0 31  7  0  0  1  4  1  2  2  0  1  1  2]\n",
      " [ 7  5  0  0  3 27  1  0  6 11  0  4  0  9  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  7  0  0  0  0  0  0 45  1  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  0  0  3  2  0  2 44  1  1  3  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  3  5  1  0  3  1  0 38  0  1  0  0  0]\n",
      " [ 0  1  2  0  1  1  2  0  0  0  1  0 57  1  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0 56  0  0]\n",
      " [ 3  1  2  0  2  3  0  1  1  2  1  0  0  5  0 42  0]\n",
      " [ 0  0  2  6  0  0  0  2  1  0  0  0  0  0  0  0 58]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.646125116713352\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56        68\n",
      "           1       0.76      0.85      0.80        72\n",
      "           2       0.63      0.70      0.67        57\n",
      "           3       0.78      0.72      0.75        58\n",
      "           4       0.38      0.35      0.36        66\n",
      "           5       0.35      0.22      0.27        76\n",
      "           6       0.86      0.83      0.84        71\n",
      "           7       0.92      0.75      0.83        61\n",
      "           8       0.79      0.70      0.74        53\n",
      "           9       0.52      0.57      0.55        61\n",
      "          10       0.68      0.83      0.75        63\n",
      "          11       0.57      0.68      0.62        53\n",
      "          12       0.55      0.68      0.61        68\n",
      "          13       0.61      0.67      0.64        55\n",
      "          14       0.80      0.84      0.82        57\n",
      "          15       0.53      0.48      0.50        63\n",
      "          16       0.71      0.67      0.69        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.65      0.65      1071\n",
      "weighted avg       0.64      0.65      0.64      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  3  0  0  1  8  0  0  3  1  9  3  1  1  0  1  0]\n",
      " [ 0 61  0  0  1  3  0  0  1  0  0  2  1  2  0  1  0]\n",
      " [ 0  0 40  1  2  1  1  0  0  2  0  0  3  0  0  2  5]\n",
      " [ 0  0  0 42  1  0  0  2  0  0  0  0  3  0  5  0  5]\n",
      " [ 5  2  7  0 23  4  2  0  2  4  2  2  5  1  1  3  3]\n",
      " [ 6  5  0  0 10 17  1  0  3  8  3  6  4  6  0  7  0]\n",
      " [ 0  0  3  0  4  1 59  0  0  1  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  3  3  0  0 46  0  0  0  0  2  0  4  0  3]\n",
      " [ 1  7  0  0  0  1  0  0 37  1  4  0  1  0  0  1  0]\n",
      " [12  0  0  0  0  2  2  0  0 35  0  2  2  2  0  4  0]\n",
      " [ 1  1  1  0  0  1  0  0  0  4 52  0  1  1  0  1  0]\n",
      " [ 1  0  0  0  2  1  2  0  1  3  2 36  3  1  0  1  0]\n",
      " [ 1  0  1  1  3  1  1  0  0  5  1  2 46  1  1  2  2]\n",
      " [ 1  0  4  0  1  3  0  0  0  3  0  2  2 37  0  2  0]\n",
      " [ 0  0  2  1  0  0  0  0  0  0  0  0  5  0 48  0  1]\n",
      " [ 0  1  2  0  4  5  0  0  0  0  2  8  2  9  0 30  0]\n",
      " [ 0  0  3  6  6  1  1  2  0  0  0  0  1  0  1  2 46]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.44537815126050423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.56        68\n",
      "           1       0.52      0.83      0.64        72\n",
      "           2       0.28      0.53      0.37        57\n",
      "           3       0.53      0.33      0.40        58\n",
      "           4       0.18      0.09      0.12        66\n",
      "           5       0.37      0.25      0.30        76\n",
      "           6       0.00      0.00      0.00        71\n",
      "           7       0.85      0.92      0.88        61\n",
      "           8       0.65      0.74      0.69        53\n",
      "           9       0.23      0.11      0.15        61\n",
      "          10       0.44      0.81      0.57        63\n",
      "          11       0.48      0.47      0.48        53\n",
      "          12       0.20      0.35      0.26        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.64      0.89      0.74        57\n",
      "          15       0.32      0.33      0.33        63\n",
      "          16       0.44      0.49      0.46        69\n",
      "\n",
      "    accuracy                           0.45      1071\n",
      "   macro avg       0.40      0.45      0.41      1071\n",
      "weighted avg       0.39      0.45      0.40      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35  6  0  0  1  3  0  0  3  1 16  2  0  0  0  1  0]\n",
      " [ 0 60  0  0  0  3  0  0  5  0  0  0  3  0  0  1  0]\n",
      " [ 0  1 30  3  2  0  0  0  0  0  1  0 11  0  0  3  6]\n",
      " [ 0  1  0 19  0  0  0  1  0  1  0  0  1  0 15  0 20]\n",
      " [ 3  6  9  3  6  4  0  0  1  3  5  3 10  0  1  6  6]\n",
      " [ 8  8  0  0  1 19  0  0  2  9  5 10  7  0  0  7  0]\n",
      " [ 0  0 30  0 11  0  0  0  0  2 10  1 15  0  0  0  2]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  2  0  2]\n",
      " [ 1  7  0  0  0  2  0  0 39  2  1  0  1  0  0  0  0]\n",
      " [ 4  2  3  0  2  6  0  0  3  7 13  4 11  0  0  6  0]\n",
      " [ 5  5  0  0  0  0  0  0  0  1 51  0  1  0  0  0  0]\n",
      " [ 0  3  3  0  5  4  0  0  3  0  0 25  5  0  0  5  0]\n",
      " [ 1  6 12  0  2  0  0  0  1  0  8  0 24  0  6  4  4]\n",
      " [ 0  7  3  0  2  2  0  0  3  2  3  4 17  0  0 12  0]\n",
      " [ 0  0  0  1  0  0  0  3  0  0  0  0  0  0 51  0  2]\n",
      " [ 0  2  5  0  2  8  0  0  0  2  4  3 14  0  0 21  2]\n",
      " [ 0  1 12  9  0  1  0  6  0  1  0  0  0  0  5  0 34]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.23436041083099907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.60      0.75        72\n",
      "           2       0.28      0.56      0.37        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.29      0.79      0.42        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.17      1.00      0.28        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.41      0.24        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.14      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0 65  0  3  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0 17  0 12  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 42  0 24  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0 56  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 22  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 29  0 26  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 17  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0 24  0 10  0 10  0  0  0  0  0  8]\n",
      " [ 0  0  1  0  0  0 25  0 13  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  8  0  0  0 15  0 25  0 15  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.7124183006535948\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        68\n",
      "           1       0.73      0.94      0.82        72\n",
      "           2       0.60      0.82      0.70        57\n",
      "           3       0.77      0.83      0.80        58\n",
      "           4       0.57      0.20      0.29        66\n",
      "           5       0.44      0.37      0.40        76\n",
      "           6       0.84      1.00      0.91        71\n",
      "           7       0.97      0.97      0.97        61\n",
      "           8       0.71      0.75      0.73        53\n",
      "           9       0.43      0.39      0.41        61\n",
      "          10       0.79      0.95      0.86        63\n",
      "          11       0.73      0.62      0.67        53\n",
      "          12       0.74      0.63      0.68        68\n",
      "          13       0.63      0.87      0.73        55\n",
      "          14       0.88      0.98      0.93        57\n",
      "          15       0.66      0.49      0.56        63\n",
      "          16       0.80      0.65      0.72        69\n",
      "\n",
      "    accuracy                           0.71      1071\n",
      "   macro avg       0.70      0.72      0.70      1071\n",
      "weighted avg       0.70      0.71      0.70      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49  4  0  0  1  3  0  0  0  3  5  3  0  0  0  0  0]\n",
      " [ 0 68  0  0  0  0  0  0  1  0  0  0  0  3  0  0  0]\n",
      " [ 0  0 47  3  0  1  3  0  0  0  0  0  1  0  0  1  1]\n",
      " [ 0  0  0 48  2  0  0  1  0  0  0  0  1  0  3  0  3]\n",
      " [ 4  2 12  0 13  9  1  0  1  8  2  2  2  3  1  4  2]\n",
      " [ 7  4  0  0  2 28  0  0  6 11  0  1  2 13  0  2  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 59  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 10  0  0  0  1  0  0 40  0  2  0  0  0  0  0  0]\n",
      " [ 4  0  3  0  2  5  4  0  4 24  4  0  5  1  0  5  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  0  3  3  0  2  4  0 33  0  2  0  1  0]\n",
      " [ 0  0  4  1  0  3  1  0  1  2  2  1 43  2  2  2  4]\n",
      " [ 1  0  1  0  0  2  0  0  1  0  0  1  0 48  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 4  1  2  0  2  8  0  0  0  4  1  4  1  4  0 31  1]\n",
      " [ 0  0  8  9  1  0  2  1  0  0  0  0  2  0  1  0 45]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.49019607843137253\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51        68\n",
      "           1       0.51      0.57      0.54        72\n",
      "           2       0.43      0.44      0.43        57\n",
      "           3       0.51      0.60      0.56        58\n",
      "           4       0.29      0.17      0.21        66\n",
      "           5       0.31      0.29      0.30        76\n",
      "           6       0.60      0.94      0.73        71\n",
      "           7       0.84      0.92      0.88        61\n",
      "           8       0.41      0.57      0.47        53\n",
      "           9       0.25      0.10      0.14        61\n",
      "          10       0.57      0.71      0.63        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.30      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.91      0.73        57\n",
      "          15       0.36      0.22      0.27        63\n",
      "          16       0.56      0.33      0.42        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.47      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36  3  0  0  0  7  0  0  5  1 10  4  0  2  0  0  0]\n",
      " [ 2 41  0  0  0  6  0  0 18  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  0  0  0  2  0  5  1  2  2  4]\n",
      " [ 0  0  2 35  0  0  1  1  0  0  0  0  0  0 10  0  9]\n",
      " [ 5  4  8  3 11  9  7  1  4  3  0  3  3  2  1  1  1]\n",
      " [ 6  9  0  0  2 22  1  0  2  9  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  1 67  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 56  0  0  0  0  0  0  3  0  0]\n",
      " [ 3 12  0  0  0  1  0  0 30  0  6  0  0  1  0  0  0]\n",
      " [ 9  1  0  0  3  8  8  0  1  6  3  7  6  6  0  3  0]\n",
      " [ 7  2  0  0  1  0  3  0  2  2 45  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  5  6  3  0  4  1  0 24  1  2  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  3  0  3  0  0  0  5  1  1  4  4 27  0  4  0]\n",
      " [ 0  0  0  4  0  0  0  0  0  0  0  0  0  0 52  0  1]\n",
      " [ 3  3  3  0  6  6  1  3  0  1  3  7  4  7  1 14  1]\n",
      " [ 0  0  9 16  0  1  5  6  0  0  2  0  0  0  7  0 23]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6442577030812325\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58        68\n",
      "           1       0.61      0.83      0.70        72\n",
      "           2       0.62      0.74      0.67        57\n",
      "           3       0.68      0.88      0.77        58\n",
      "           4       0.48      0.20      0.28        66\n",
      "           5       0.41      0.29      0.34        76\n",
      "           6       0.70      0.94      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.66      0.81      0.73        53\n",
      "           9       0.37      0.31      0.34        61\n",
      "          10       0.81      0.86      0.83        63\n",
      "          11       0.84      0.49      0.62        53\n",
      "          12       0.67      0.53      0.59        68\n",
      "          13       0.52      0.85      0.64        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.61      0.43      0.50        63\n",
      "          16       0.75      0.48      0.58        69\n",
      "\n",
      "    accuracy                           0.64      1071\n",
      "   macro avg       0.64      0.65      0.63      1071\n",
      "weighted avg       0.64      0.64      0.62      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[40  5  0  0  0  5  0  0  2  4  7  1  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  0  4  0  0  0  0  0  2  0  0  4  1]\n",
      " [ 0  0  1 51  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 3  7  7  1 13  7  5  2  1  7  2  1  5  3  1  1  0]\n",
      " [10  8  1  0  2 22  2  1  4 11  0  1  1 12  0  1  0]\n",
      " [ 0  0  0  0  0  0 67  0  0  1  1  0  0  0  0  1  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 7  1  1  0  1  6  7  1  3 19  1  0  4  6  0  4  0]\n",
      " [ 1  1  4  0  0  0  0  0  0  2 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  3  1 26  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  0  7  0  2  0  1  1 36  3  4  1  5]\n",
      " [ 0  3  0  0  1  1  0  0  2  1  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  0  0 53  0  1]\n",
      " [ 5  2  3  1  2  4  0  0  0  3  0  1  4 10  1 27  0]\n",
      " [ 0  0  8 16  1  2  2  1  0  0  0  0  0  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8160597572362278\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        68\n",
      "           1       0.75      0.99      0.85        72\n",
      "           2       0.75      0.98      0.85        57\n",
      "           3       0.86      0.93      0.89        58\n",
      "           4       0.74      0.47      0.57        66\n",
      "           5       0.60      0.42      0.50        76\n",
      "           6       0.96      1.00      0.98        71\n",
      "           7       0.93      0.92      0.93        61\n",
      "           8       0.75      0.85      0.80        53\n",
      "           9       0.67      0.64      0.66        61\n",
      "          10       0.88      0.95      0.92        63\n",
      "          11       0.93      0.75      0.83        53\n",
      "          12       0.87      0.87      0.87        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.88      1.00      0.93        57\n",
      "          15       0.87      0.75      0.80        63\n",
      "          16       0.89      0.74      0.81        69\n",
      "\n",
      "    accuracy                           0.82      1071\n",
      "   macro avg       0.82      0.82      0.81      1071\n",
      "weighted avg       0.81      0.82      0.81      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55  5  0  0  1  1  0  0  1  2  1  0  0  1  0  1  0]\n",
      " [ 0 71  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 54  0  0  0  1  0  0  0  0  0  0  2  0  1]\n",
      " [ 3  2  6  1 31  7  0  0  2  2  2  2  2  1  1  1  3]\n",
      " [ 5  6  0  0  2 32  1  0  5 10  0  0  2 10  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  3  0  1]\n",
      " [ 0  7  0  0  0  0  0  0 45  1  0  0  0  0  0  0  0]\n",
      " [ 3  1  2  0  2  4  1  0  2 39  3  0  4  0  0  0  0]\n",
      " [ 1  0  0  0  2  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  6  0  0  2  2  1 40  0  1  0  0  0]\n",
      " [ 0  1  2  0  1  0  1  0  0  0  1  0 59  0  2  1  0]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 50  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 4  2  0  0  2  2  0  1  0  2  0  1  0  2  0 47  0]\n",
      " [ 0  0  7  7  0  1  0  2  1  0  0  0  0  0  0  0 51]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6535947712418301\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56        68\n",
      "           1       0.79      0.88      0.83        72\n",
      "           2       0.64      0.75      0.69        57\n",
      "           3       0.77      0.71      0.74        58\n",
      "           4       0.39      0.36      0.38        66\n",
      "           5       0.38      0.24      0.29        76\n",
      "           6       0.88      0.86      0.87        71\n",
      "           7       0.91      0.80      0.85        61\n",
      "           8       0.79      0.70      0.74        53\n",
      "           9       0.52      0.52      0.52        61\n",
      "          10       0.71      0.87      0.79        63\n",
      "          11       0.51      0.66      0.58        53\n",
      "          12       0.57      0.69      0.63        68\n",
      "          13       0.64      0.64      0.64        55\n",
      "          14       0.80      0.82      0.81        57\n",
      "          15       0.50      0.40      0.44        63\n",
      "          16       0.71      0.71      0.71        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.65      1071\n",
      "weighted avg       0.65      0.65      0.65      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[39  2  0  0  1  6  0  0  3  1 10  5  1  0  0  0  0]\n",
      " [ 1 63  0  0  0  1  0  0  1  0  0  5  1  0  0  0  0]\n",
      " [ 0  0 43  1  1  1  1  0  0  2  0  0  2  0  0  1  5]\n",
      " [ 0  0  0 41  1  0  0  2  0  0  0  0  3  0  6  0  5]\n",
      " [ 5  2  6  0 24  4  1  0  1  5  2  3  4  1  1  3  4]\n",
      " [ 7  3  0  0  9 18  1  0  3  8  2  6  4  8  0  7  0]\n",
      " [ 0  0  1  0  2  1 61  0  0  1  3  0  2  0  0  0  0]\n",
      " [ 0  0  1  4  2  0  0 49  0  0  0  0  1  0  3  0  1]\n",
      " [ 1  6  0  0  1  2  0  0 37  1  3  0  1  0  0  1  0]\n",
      " [12  0  1  0  3  3  1  0  0 32  0  1  3  1  0  3  1]\n",
      " [ 1  1  0  0  0  0  0  0  1  2 55  0  2  0  0  1  0]\n",
      " [ 1  2  0  0  3  2  3  0  1  1  1 35  2  2  0  0  0]\n",
      " [ 1  0  1  1  5  2  1  0  0  2  0  2 47  0  1  3  2]\n",
      " [ 2  0  3  0  0  2  0  0  0  4  1  3  2 35  0  3  0]\n",
      " [ 0  0  2  1  1  0  0  0  0  0  0  0  5  0 47  0  1]\n",
      " [ 1  1  4  0  5  6  0  0  0  2  0  8  2  8  0 25  1]\n",
      " [ 0  0  5  5  3  0  0  3  0  0  0  0  0  0  1  3 49]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.44537815126050423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.56        68\n",
      "           1       0.52      0.83      0.64        72\n",
      "           2       0.28      0.53      0.37        57\n",
      "           3       0.53      0.33      0.40        58\n",
      "           4       0.18      0.09      0.12        66\n",
      "           5       0.37      0.25      0.30        76\n",
      "           6       0.00      0.00      0.00        71\n",
      "           7       0.85      0.92      0.88        61\n",
      "           8       0.65      0.74      0.69        53\n",
      "           9       0.23      0.11      0.15        61\n",
      "          10       0.44      0.81      0.57        63\n",
      "          11       0.48      0.47      0.48        53\n",
      "          12       0.20      0.35      0.26        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.64      0.89      0.74        57\n",
      "          15       0.32      0.33      0.33        63\n",
      "          16       0.44      0.49      0.46        69\n",
      "\n",
      "    accuracy                           0.45      1071\n",
      "   macro avg       0.40      0.45      0.41      1071\n",
      "weighted avg       0.39      0.45      0.40      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35  6  0  0  1  3  0  0  3  1 16  2  0  0  0  1  0]\n",
      " [ 0 60  0  0  0  3  0  0  5  0  0  0  3  0  0  1  0]\n",
      " [ 0  1 30  3  2  0  0  0  0  0  1  0 11  0  0  3  6]\n",
      " [ 0  1  0 19  0  0  0  1  0  1  0  0  1  0 15  0 20]\n",
      " [ 3  6  9  3  6  4  0  0  1  3  5  3 10  0  1  6  6]\n",
      " [ 8  8  0  0  1 19  0  0  2  9  5 10  7  0  0  7  0]\n",
      " [ 0  0 30  0 11  0  0  0  0  2 10  1 15  0  0  0  2]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  2  0  2]\n",
      " [ 1  7  0  0  0  2  0  0 39  2  1  0  1  0  0  0  0]\n",
      " [ 4  2  3  0  2  6  0  0  3  7 13  4 11  0  0  6  0]\n",
      " [ 5  5  0  0  0  0  0  0  0  1 51  0  1  0  0  0  0]\n",
      " [ 0  3  3  0  5  4  0  0  3  0  0 25  5  0  0  5  0]\n",
      " [ 1  6 12  0  2  0  0  0  1  0  8  0 24  0  6  4  4]\n",
      " [ 0  7  3  0  2  2  0  0  3  2  3  4 17  0  0 12  0]\n",
      " [ 0  0  0  1  0  0  0  3  0  0  0  0  0  0 51  0  2]\n",
      " [ 0  2  5  0  2  8  0  0  0  2  4  3 14  0  0 21  2]\n",
      " [ 0  1 12  9  0  1  0  6  0  1  0  0  0  0  5  0 34]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.23436041083099907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.60      0.75        72\n",
      "           2       0.28      0.56      0.37        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.29      0.79      0.42        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.17      1.00      0.28        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.41      0.24        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.14      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0 65  0  3  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0 17  0 12  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 42  0 24  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0 56  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 22  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 29  0 26  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 17  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0 24  0 10  0 10  0  0  0  0  0  8]\n",
      " [ 0  0  1  0  0  0 25  0 13  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  8  0  0  0 15  0 25  0 15  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.7133520074696545\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69        68\n",
      "           1       0.72      0.94      0.81        72\n",
      "           2       0.60      0.84      0.70        57\n",
      "           3       0.77      0.88      0.82        58\n",
      "           4       0.68      0.20      0.31        66\n",
      "           5       0.43      0.38      0.41        76\n",
      "           6       0.82      0.97      0.89        71\n",
      "           7       0.97      0.97      0.97        61\n",
      "           8       0.71      0.75      0.73        53\n",
      "           9       0.52      0.44      0.48        61\n",
      "          10       0.81      0.94      0.87        63\n",
      "          11       0.71      0.60      0.65        53\n",
      "          12       0.73      0.60      0.66        68\n",
      "          13       0.60      0.82      0.69        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.69      0.49      0.57        63\n",
      "          16       0.78      0.68      0.73        69\n",
      "\n",
      "    accuracy                           0.71      1071\n",
      "   macro avg       0.71      0.72      0.70      1071\n",
      "weighted avg       0.71      0.71      0.70      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49  4  0  0  1  4  0  0  0  4  4  1  0  1  0  0  0]\n",
      " [ 0 68  0  0  0  0  0  0  2  0  0  0  0  2  0  0  0]\n",
      " [ 0  0 48  2  0  1  3  0  0  0  0  0  0  0  0  0  3]\n",
      " [ 0  0  0 51  1  0  0  1  0  0  0  0  1  0  2  0  2]\n",
      " [ 5  2 13  1 13  9  1  0  1  4  2  2  3  3  1  4  2]\n",
      " [ 9  4  0  0  0 29  1  0  5  9  0  2  2 13  0  2  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  0 59  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 10  0  0  0  1  0  0 40  0  2  0  0  0  0  0  0]\n",
      " [ 2  0  4  0  1  5  4  0  4 27  3  1  5  2  0  3  0]\n",
      " [ 3  1  0  0  0  0  0  0  0  0 59  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  0  4  3  0  2  4  0 32  0  2  0  1  0]\n",
      " [ 0  1  4  2  0  3  1  0  1  1  2  1 41  3  2  2  4]\n",
      " [ 1  1  2  0  0  2  0  0  1  0  0  1  0 45  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 4  1  2  0  2  9  0  0  0  3  0  5  1  4  0 31  1]\n",
      " [ 0  0  6  9  1  0  2  1  0  0  0  0  2  0  1  0 47]]\n",
      "==================================================\n",
      "Best Model: Random Forest Classifier\n",
      "Best Accuracy: 0.8160597572362278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize variables to store the best model and its accuracy\n",
    "best_model_name = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    # Update the best model if the current one is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = name\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(\"=\"*50)\n",
    "print(\"Best Model:\", best_model_name)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model: 0.8179271708683473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy of the best model:\", accuracy_score(y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  12\n",
      "Actual:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Label: \", model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"Actual: \", y_test.iloc[10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler, open(\"Models/scaler.pkl\", 'wb'))\n",
    "pickle.dump(model, open(\"Models/model.pkl\", 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "\n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "\n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "\n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "\n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "\n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "\n",
    "    return top_classes_names_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "being a Teacher, with probability of 0.59\n",
      "being a Business Owner, with probability of 0.2\n",
      "being a Unknown, with probability of 0.08\n",
      "being a Government Officer, with probability of 0.06\n",
      "being a Real Estate Developer, with probability of 0.05\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"being a {class_name}, with probability of {probability}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
